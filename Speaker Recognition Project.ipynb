{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "76d432b6-aa46-4201-941d-767ddd501930",
   "metadata": {},
   "source": [
    "# Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f931ff29-a52c-45e0-af73-1a2d1311f41d",
   "metadata": {},
   "source": [
    "This example demonstrates how to create a model to classify speakers from the frequency domain representation of speech recordings, obtained via Fast Fourier Transform (FFT).\n",
    "\n",
    "It shows the following:\n",
    "\n",
    "How to use tf.data to load, preprocess and feed audio streams into a model\n",
    "How to create a 1D convolutional network with residual connections for audio classification.\n",
    "\n",
    "Our process:\n",
    "\n",
    "We prepare a dataset of speech samples from different speakers, with the speaker as label.\n",
    "We add background noise to these samples to augment our data.\n",
    "We take the FFT of these samples.\n",
    "We train a 1D convnet to predict the correct speaker given a noisy FFT speech sample.\n",
    "\n",
    "Note:\n",
    "\n",
    "This example should be run with TensorFlow 2.3 or higher, or tf-nightly.\n",
    "The noise samples in the dataset need to be resampled to a sampling rate of 16000 Hz before using the code in this example. In order to do this, you will need to have installed ffmpg."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4e6c744b-41ea-4b2c-a5e0-414f1f38c487",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import numpy as np\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "from pathlib import Path\n",
    "from IPython.display import display, Audio\n",
    "\n",
    "# Get the data from https://www.kaggle.com/kongaevans/speaker-recognition-dataset/download\n",
    "# and save it to the 'Downloads' folder in your HOME directory\n",
    "DATASET_ROOT = os.path.join(os.path.expanduser(\"~\"), \"Downloads/16000_pcm_speeches\")\n",
    "\n",
    "# The folders in which we will put the audio samples and the noise samples\n",
    "AUDIO_SUBFOLDER = \"audio\"\n",
    "NOISE_SUBFOLDER = \"noise\"\n",
    "\n",
    "DATASET_AUDIO_PATH = os.path.join(DATASET_ROOT, AUDIO_SUBFOLDER)\n",
    "DATASET_NOISE_PATH = os.path.join(DATASET_ROOT, NOISE_SUBFOLDER)\n",
    "\n",
    "# Percentage of samples to use for validation\n",
    "VALID_SPLIT = 0.1\n",
    "\n",
    "# Seed to use when shuffling the dataset and the noise\n",
    "SHUFFLE_SEED = 43\n",
    "\n",
    "# The sampling rate to use.\n",
    "# This is the one used in all of the audio samples.\n",
    "# We will resample all of the noise to this sampling rate.\n",
    "# This will also be the output size of the audio wave samples\n",
    "# (since all samples are of 1 second long)\n",
    "SAMPLING_RATE = 16000\n",
    "\n",
    "# The factor to multiply the noise with according to:\n",
    "#   noisy_sample = sample + noise * prop * scale\n",
    "#      where prop = sample_amplitude / noise_amplitude\n",
    "SCALE = 0.5\n",
    "\n",
    "BATCH_SIZE = 128\n",
    "EPOCHS = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0aa75eb-a9ca-4143-9a18-93ce15f2b7e0",
   "metadata": {},
   "source": [
    "# Data preparation\n",
    "\n",
    "### The dataset is composed of 7 folders, divided into 2 groups:\n",
    "\n",
    "- Speech samples, with 5 folders for 5 different speakers. Each folder contains 1500 audio files, each 1 second long and sampled at 16000 Hz.\n",
    "- Background noise samples, with 2 folders and a total of 6 files. These files are longer than 1 second (and originally not sampled at 16000 Hz, but we will resample them to 16000 Hz). We will use those 6 files to create 354 1-second-long noise samples to be used for training.\n",
    "\n",
    "### Let's sort these 2 categories into 2 folders:\n",
    "\n",
    "- An audio folder which will contain all the per-speaker speech sample folders\n",
    "- A noise folder which will contain all the noise samples\n",
    "\n",
    "Before sorting the audio and noise categories into 2 folders,"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35a95e1a-f5a8-46e9-ba16-30504d685525",
   "metadata": {},
   "source": [
    "main_directory/\n",
    "    \n",
    "    ...speaker_juan/\n",
    "    \n",
    "    ...speaker_hom/\n",
    "    \n",
    "    ...speaker_mike/\n",
    "    \n",
    "    ...speaker_ed/\n",
    "    \n",
    "    ...speaker_dan/\n",
    "    \n",
    "    ...other/\n",
    "    \n",
    "    ..._background_noise_/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49b29b70-01d4-4e9c-bbcb-bd3c9d38031b",
   "metadata": {},
   "source": [
    "After sorting, we end up with the following structure:\n",
    "    \n",
    "main_directory/\n",
    "\n",
    "...audio/\n",
    "\n",
    "......speaker_juan/\n",
    "\n",
    "......speaker_hom/\n",
    "\n",
    "......speaker_mike/\n",
    "\n",
    "......speaker_ed/\n",
    "\n",
    "......speaker_dan/\n",
    "\n",
    "...noise/\n",
    "\n",
    "......other/\n",
    "\n",
    "......_background_noise_/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c0e54abf-aa4d-4649-979b-30c4bde1c9ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\Mike\\\\Documents\\\\AI - Math II\\\\Project'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a385fa5c-50b0-469a-a1c4-14a0c00b9f15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If folder `audio`, does not exist, create it, otherwise do nothing\n",
    "if os.path.exists(DATASET_AUDIO_PATH) is False:\n",
    "    os.makedirs(DATASET_AUDIO_PATH)\n",
    "\n",
    "# If folder `noise`, does not exist, create it, otherwise do nothing\n",
    "if os.path.exists(DATASET_NOISE_PATH) is False:\n",
    "    os.makedirs(DATASET_NOISE_PATH)\n",
    "\n",
    "for folder in os.listdir(DATASET_ROOT):\n",
    "    if os.path.isdir(os.path.join(DATASET_ROOT, folder)):\n",
    "        if folder in [AUDIO_SUBFOLDER, NOISE_SUBFOLDER]:\n",
    "            # If folder is `audio` or `noise`, do nothing\n",
    "            continue\n",
    "        elif folder in [\"other\", \"_background_noise_\"]:\n",
    "            # If folder is one of the folders that contains noise samples,\n",
    "            # move it to the `noise` folder\n",
    "            shutil.move(\n",
    "                os.path.join(DATASET_ROOT, folder),\n",
    "                os.path.join(DATASET_NOISE_PATH, folder),\n",
    "            )\n",
    "        else:\n",
    "            # Otherwise, it should be a speaker folder, then move it to\n",
    "            # `audio` folder\n",
    "            shutil.move(\n",
    "                os.path.join(DATASET_ROOT, folder),\n",
    "                os.path.join(DATASET_AUDIO_PATH, folder),\n",
    "            )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "574228c1-1cdd-42d8-a09f-0ecaca444c78",
   "metadata": {},
   "source": [
    "# Noise preparation\n",
    "In this section:\n",
    "\n",
    "- We load all noise samples (which should have been resampled to 16000)\n",
    "- We split those noise samples to chuncks of 16000 samples which correspond to 1 second duration each"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d7c2756a-d45b-4aa8-802a-0888cb5f5d9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 0 files belonging to 0 directories\n"
     ]
    }
   ],
   "source": [
    "# Get the list of all noise files\n",
    "noise_paths = []\n",
    "for subdir in os.listdir(DATASET_NOISE_PATH):\n",
    "    subdir_path = Path(DATASET_NOISE_PATH) / subdir\n",
    "    if os.path.isdir(subdir_path):\n",
    "        noise_paths += [\n",
    "            os.path.join(subdir_path, filepath)\n",
    "            for filepath in os.listdir(subdir_path)\n",
    "            if filepath.endswith(\".wav\")\n",
    "        ]\n",
    "\n",
    "print(\n",
    "    \"Found {} files belonging to {} directories\".format(\n",
    "        len(noise_paths), len(os.listdir(DATASET_NOISE_PATH))\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ef12ede-492c-4219-b57e-6543937409d0",
   "metadata": {},
   "source": [
    "Resample all noise samples to 16000 Hz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "68d9f88f-e5ca-44e0-9833-72307f275eb4",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_5520/2556080820.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     37\u001b[0m print(\n\u001b[0;32m     38\u001b[0m     \"{} noise files were split into {} noise samples where each is {} sec. long\".format(\n\u001b[1;32m---> 39\u001b[1;33m         \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnoise_paths\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnoises\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnoises\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m//\u001b[0m \u001b[0mSAMPLING_RATE\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     40\u001b[0m     )\n\u001b[0;32m     41\u001b[0m )\n",
      "\u001b[1;32m~\\.conda\\envs\\tf-gpu\\lib\\site-packages\\tensorflow\\python\\framework\\tensor_shape.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m    894\u001b[0m       \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    895\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_v2_behavior\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 896\u001b[1;33m           \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dims\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    897\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    898\u001b[0m           \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dims\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "command = (\n",
    "    \"for dir in `ls -1 \" + DATASET_NOISE_PATH + \"`; do \"\n",
    "    \"for file in `ls -1 \" + DATASET_NOISE_PATH + \"/$dir/*.wav`; do \"\n",
    "    \"sample_rate=`ffprobe -hide_banner -loglevel panic -show_streams \"\n",
    "    \"$file | grep sample_rate | cut -f2 -d=`; \"\n",
    "    \"if [ $sample_rate -ne 16000 ]; then \"\n",
    "    \"ffmpeg -hide_banner -loglevel panic -y \"\n",
    "    \"-i $file -ar 16000 temp.wav; \"\n",
    "    \"mv temp.wav $file; \"\n",
    "    \"fi; done; done\"\n",
    ")\n",
    "\n",
    "os.system(command)\n",
    "\n",
    "# Split noise into chunks of 16000 each\n",
    "def load_noise_sample(path):\n",
    "    sample, sampling_rate = tf.audio.decode_wav(\n",
    "        tf.io.read_file(path), desired_channels=1\n",
    "    )\n",
    "    if sampling_rate == SAMPLING_RATE:\n",
    "        # Number of slices of 16000 each that can be generated from the noise sample\n",
    "        slices = int(sample.shape[0] / SAMPLING_RATE)\n",
    "        sample = tf.split(sample[: slices * SAMPLING_RATE], slices)\n",
    "        return sample\n",
    "    else:\n",
    "        print(\"Sampling rate for {} is incorrect. Ignoring it\".format(path))\n",
    "        return None\n",
    "\n",
    "\n",
    "noises = []\n",
    "for path in noise_paths:\n",
    "    sample = load_noise_sample(path)\n",
    "    if sample:\n",
    "        noises.extend(sample)\n",
    "noises = tf.stack(noises)\n",
    "\n",
    "print(\n",
    "    \"{} noise files were split into {} noise samples where each is {} sec. long\".format(\n",
    "        len(noise_paths), noises.shape[0], noises.shape[1] // SAMPLING_RATE\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f04fec1e-861c-46d1-a010-e152c93fd8b2",
   "metadata": {},
   "source": [
    "# Dataset generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e340166-0d7e-4104-86be-9cde9d09fa6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def paths_and_labels_to_dataset(audio_paths, labels):\n",
    "    \"\"\"Constructs a dataset of audios and labels.\"\"\"\n",
    "    path_ds = tf.data.Dataset.from_tensor_slices(audio_paths)\n",
    "    audio_ds = path_ds.map(lambda x: path_to_audio(x))\n",
    "    label_ds = tf.data.Dataset.from_tensor_slices(labels)\n",
    "    return tf.data.Dataset.zip((audio_ds, label_ds))\n",
    "\n",
    "\n",
    "def path_to_audio(path):\n",
    "    \"\"\"Reads and decodes an audio file.\"\"\"\n",
    "    audio = tf.io.read_file(path)\n",
    "    audio, _ = tf.audio.decode_wav(audio, 1, SAMPLING_RATE)\n",
    "    return audio\n",
    "\n",
    "\n",
    "def add_noise(audio, noises=None, scale=0.5):\n",
    "    if noises is not None:\n",
    "        # Create a random tensor of the same size as audio ranging from\n",
    "        # 0 to the number of noise stream samples that we have.\n",
    "        tf_rnd = tf.random.uniform(\n",
    "            (tf.shape(audio)[0],), 0, noises.shape[0], dtype=tf.int32\n",
    "        )\n",
    "        noise = tf.gather(noises, tf_rnd, axis=0)\n",
    "\n",
    "        # Get the amplitude proportion between the audio and the noise\n",
    "        prop = tf.math.reduce_max(audio, axis=1) / tf.math.reduce_max(noise, axis=1)\n",
    "        prop = tf.repeat(tf.expand_dims(prop, axis=1), tf.shape(audio)[1], axis=1)\n",
    "\n",
    "        # Adding the rescaled noise to audio\n",
    "        audio = audio + noise * prop * scale\n",
    "\n",
    "    return audio\n",
    "\n",
    "\n",
    "def audio_to_fft(audio):\n",
    "    # Since tf.signal.fft applies FFT on the innermost dimension,\n",
    "    # we need to squeeze the dimensions and then expand them again\n",
    "    # after FFT\n",
    "    audio = tf.squeeze(audio, axis=-1)\n",
    "    fft = tf.signal.fft(\n",
    "        tf.cast(tf.complex(real=audio, imag=tf.zeros_like(audio)), tf.complex64)\n",
    "    )\n",
    "    fft = tf.expand_dims(fft, axis=-1)\n",
    "\n",
    "    # Return the absolute value of the first half of the FFT\n",
    "    # which represents the positive frequencies\n",
    "    return tf.math.abs(fft[:, : (audio.shape[1] // 2), :])\n",
    "\n",
    "\n",
    "# Get the list of audio file paths along with their corresponding labels\n",
    "\n",
    "class_names = os.listdir(DATASET_AUDIO_PATH)\n",
    "print(\"Our class names: {}\".format(class_names,))\n",
    "\n",
    "audio_paths = []\n",
    "labels = []\n",
    "for label, name in enumerate(class_names):\n",
    "    print(\"Processing speaker {}\".format(name,))\n",
    "    dir_path = Path(DATASET_AUDIO_PATH) / name\n",
    "    speaker_sample_paths = [\n",
    "        os.path.join(dir_path, filepath)\n",
    "        for filepath in os.listdir(dir_path)\n",
    "        if filepath.endswith(\".wav\")\n",
    "    ]\n",
    "    audio_paths += speaker_sample_paths\n",
    "    labels += [label] * len(speaker_sample_paths)\n",
    "\n",
    "print(\n",
    "    \"Found {} files belonging to {} classes.\".format(len(audio_paths), len(class_names))\n",
    ")\n",
    "\n",
    "# Shuffle\n",
    "rng = np.random.RandomState(SHUFFLE_SEED)\n",
    "rng.shuffle(audio_paths)\n",
    "rng = np.random.RandomState(SHUFFLE_SEED)\n",
    "rng.shuffle(labels)\n",
    "\n",
    "# Split into training and validation\n",
    "num_val_samples = int(VALID_SPLIT * len(audio_paths))\n",
    "print(\"Using {} files for training.\".format(len(audio_paths) - num_val_samples))\n",
    "train_audio_paths = audio_paths[:-num_val_samples]\n",
    "train_labels = labels[:-num_val_samples]\n",
    "\n",
    "print(\"Using {} files for validation.\".format(num_val_samples))\n",
    "valid_audio_paths = audio_paths[-num_val_samples:]\n",
    "valid_labels = labels[-num_val_samples:]\n",
    "\n",
    "# Create 2 datasets, one for training and the other for validation\n",
    "train_ds = paths_and_labels_to_dataset(train_audio_paths, train_labels)\n",
    "train_ds = train_ds.shuffle(buffer_size=BATCH_SIZE * 8, seed=SHUFFLE_SEED).batch(\n",
    "    BATCH_SIZE\n",
    ")\n",
    "\n",
    "valid_ds = paths_and_labels_to_dataset(valid_audio_paths, valid_labels)\n",
    "valid_ds = valid_ds.shuffle(buffer_size=32 * 8, seed=SHUFFLE_SEED).batch(32)\n",
    "\n",
    "\n",
    "# Add noise to the training set\n",
    "train_ds = train_ds.map(\n",
    "    lambda x, y: (add_noise(x, noises, scale=SCALE), y),\n",
    "    num_parallel_calls=tf.data.AUTOTUNE,\n",
    ")\n",
    "\n",
    "# Transform audio wave to the frequency domain using `audio_to_fft`\n",
    "train_ds = train_ds.map(\n",
    "    lambda x, y: (audio_to_fft(x), y), num_parallel_calls=tf.data.AUTOTUNE\n",
    ")\n",
    "train_ds = train_ds.prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "valid_ds = valid_ds.map(\n",
    "    lambda x, y: (audio_to_fft(x), y), num_parallel_calls=tf.data.AUTOTUNE\n",
    ")\n",
    "valid_ds = valid_ds.prefetch(tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61282baf-facb-4bb1-82e5-da7064c33dd3",
   "metadata": {},
   "source": [
    "# Model Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "03f84e05-cc9d-4343-a28b-77f118584f12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input (InputLayer)              [(None, 8000, 1)]    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_1 (Conv1D)               (None, 8000, 16)     64          input[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation (Activation)         (None, 8000, 16)     0           conv1d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_2 (Conv1D)               (None, 8000, 16)     784         activation[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1d (Conv1D)                 (None, 8000, 16)     32          input[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "add (Add)                       (None, 8000, 16)     0           conv1d_2[0][0]                   \n",
      "                                                                 conv1d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 8000, 16)     0           add[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D)    (None, 4000, 16)     0           activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_4 (Conv1D)               (None, 4000, 32)     1568        max_pooling1d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 4000, 32)     0           conv1d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_5 (Conv1D)               (None, 4000, 32)     3104        activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_3 (Conv1D)               (None, 4000, 32)     544         max_pooling1d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 4000, 32)     0           conv1d_5[0][0]                   \n",
      "                                                                 conv1d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 4000, 32)     0           add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1D)  (None, 2000, 32)     0           activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_7 (Conv1D)               (None, 2000, 64)     6208        max_pooling1d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 2000, 64)     0           conv1d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_8 (Conv1D)               (None, 2000, 64)     12352       activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 2000, 64)     0           conv1d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_9 (Conv1D)               (None, 2000, 64)     12352       activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_6 (Conv1D)               (None, 2000, 64)     2112        max_pooling1d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, 2000, 64)     0           conv1d_9[0][0]                   \n",
      "                                                                 conv1d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 2000, 64)     0           add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_2 (MaxPooling1D)  (None, 1000, 64)     0           activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_11 (Conv1D)              (None, 1000, 128)    24704       max_pooling1d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 1000, 128)    0           conv1d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_12 (Conv1D)              (None, 1000, 128)    49280       activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 1000, 128)    0           conv1d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_13 (Conv1D)              (None, 1000, 128)    49280       activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_10 (Conv1D)              (None, 1000, 128)    8320        max_pooling1d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_3 (Add)                     (None, 1000, 128)    0           conv1d_13[0][0]                  \n",
      "                                                                 conv1d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, 1000, 128)    0           add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_3 (MaxPooling1D)  (None, 500, 128)     0           activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_15 (Conv1D)              (None, 500, 128)     49280       max_pooling1d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_10 (Activation)      (None, 500, 128)     0           conv1d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_16 (Conv1D)              (None, 500, 128)     49280       activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_11 (Activation)      (None, 500, 128)     0           conv1d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_17 (Conv1D)              (None, 500, 128)     49280       activation_11[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_14 (Conv1D)              (None, 500, 128)     16512       max_pooling1d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_4 (Add)                     (None, 500, 128)     0           conv1d_17[0][0]                  \n",
      "                                                                 conv1d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_12 (Activation)      (None, 500, 128)     0           add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_4 (MaxPooling1D)  (None, 250, 128)     0           activation_12[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling1d (AveragePooli (None, 83, 128)      0           max_pooling1d_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 10624)        0           average_pooling1d[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 256)          2720000     flatten[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 128)          32896       dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "output (Dense)                  (None, 0)            0           dense_1[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 3,087,952\n",
      "Trainable params: 3,087,952\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def residual_block(x, filters, conv_num=3, activation=\"relu\"):\n",
    "    # Shortcut\n",
    "    s = keras.layers.Conv1D(filters, 1, padding=\"same\")(x)\n",
    "    for i in range(conv_num - 1):\n",
    "        x = keras.layers.Conv1D(filters, 3, padding=\"same\")(x)\n",
    "        x = keras.layers.Activation(activation)(x)\n",
    "    x = keras.layers.Conv1D(filters, 3, padding=\"same\")(x)\n",
    "    x = keras.layers.Add()([x, s])\n",
    "    x = keras.layers.Activation(activation)(x)\n",
    "    return keras.layers.MaxPool1D(pool_size=2, strides=2)(x)\n",
    "\n",
    "\n",
    "def build_model(input_shape, num_classes):\n",
    "    inputs = keras.layers.Input(shape=input_shape, name=\"input\")\n",
    "\n",
    "    x = residual_block(inputs, 16, 2)\n",
    "    x = residual_block(x, 32, 2)\n",
    "    x = residual_block(x, 64, 3)\n",
    "    x = residual_block(x, 128, 3)\n",
    "    x = residual_block(x, 128, 3)\n",
    "\n",
    "    x = keras.layers.AveragePooling1D(pool_size=3, strides=3)(x)\n",
    "    x = keras.layers.Flatten()(x)\n",
    "    x = keras.layers.Dense(256, activation=\"relu\")(x)\n",
    "    x = keras.layers.Dense(128, activation=\"relu\")(x)\n",
    "\n",
    "    outputs = keras.layers.Dense(num_classes, activation=\"softmax\", name=\"output\")(x)\n",
    "\n",
    "    return keras.models.Model(inputs=inputs, outputs=outputs)\n",
    "\n",
    "\n",
    "model = build_model((SAMPLING_RATE // 2, 1), len(class_names))\n",
    "\n",
    "model.summary()\n",
    "\n",
    "# Compile the model using Adam's default learning rate\n",
    "model.compile(\n",
    "    optimizer=\"Adam\", loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"]\n",
    ")\n",
    "\n",
    "# Add callbacks:\n",
    "# 'EarlyStopping' to stop training when the model is not enhancing anymore\n",
    "# 'ModelCheckPoint' to always keep the model that has the best val_accuracy\n",
    "model_save_filename = \"model.h5\"\n",
    "\n",
    "earlystopping_cb = keras.callbacks.EarlyStopping(patience=10, restore_best_weights=True)\n",
    "mdlcheckpoint_cb = keras.callbacks.ModelCheckpoint(\n",
    "    model_save_filename, monitor=\"val_accuracy\", save_best_only=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6de6a71b-4182-4a22-9059-0ae504796da6",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fc7c0e1-6131-42c1-9435-a0c01af0d316",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(\n",
    "    train_ds,\n",
    "    epochs=EPOCHS,\n",
    "    validation_data=valid_ds,\n",
    "    callbacks=[earlystopping_cb, mdlcheckpoint_cb],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5984ba81-4184-4cb9-ac57-dbc23b16bced",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58629966-baa0-4a19-937b-06e3f9186014",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model.evaluate(valid_ds))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4aa01b9b-febc-46ac-9b59-5d9d2cdf0324",
   "metadata": {},
   "source": [
    "# Demonstration\n",
    "Let's take some samples and:\n",
    "\n",
    "- Predict the speaker\n",
    "- Compare the prediction with the real speaker\n",
    "- Listen to the audio to see that despite the samples being noisy, the model is still pretty accurate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5df8158d-cea1-4009-88c2-59e6ae611295",
   "metadata": {},
   "outputs": [],
   "source": [
    "SAMPLES_TO_DISPLAY = 10\n",
    "\n",
    "test_ds = paths_and_labels_to_dataset(valid_audio_paths, valid_labels)\n",
    "test_ds = test_ds.shuffle(buffer_size=BATCH_SIZE * 8, seed=SHUFFLE_SEED).batch(\n",
    "    BATCH_SIZE\n",
    ")\n",
    "\n",
    "test_ds = test_ds.map(lambda x, y: (add_noise(x, noises, scale=SCALE), y))\n",
    "\n",
    "for audios, labels in test_ds.take(1):\n",
    "    # Get the signal FFT\n",
    "    ffts = audio_to_fft(audios)\n",
    "    # Predict\n",
    "    y_pred = model.predict(ffts)\n",
    "    # Take random samples\n",
    "    rnd = np.random.randint(0, BATCH_SIZE, SAMPLES_TO_DISPLAY)\n",
    "    audios = audios.numpy()[rnd, :, :]\n",
    "    labels = labels.numpy()[rnd]\n",
    "    y_pred = np.argmax(y_pred, axis=-1)[rnd]\n",
    "\n",
    "    for index in range(SAMPLES_TO_DISPLAY):\n",
    "        # For every sample, print the true and predicted label\n",
    "        # as well as run the voice with the noise\n",
    "        print(\n",
    "            \"Speaker: {} - Predicted: {}\".format(\n",
    "                class_names[labels[index]],\n",
    "                class_names[y_pred[index]],\n",
    "            )\n",
    "        )\n",
    "        display(Audio(audios[index, :, :].squeeze(), rate=SAMPLING_RATE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f46d73b-c907-4c59-bc94-0603f5af59da",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
