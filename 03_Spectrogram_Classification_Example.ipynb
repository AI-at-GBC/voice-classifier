{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "03 - Spectrogram Classification Example.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yq_t4O4bmuck",
        "outputId": "3f4ff312-a777-4fe1-ea8b-92ef6b934a1c"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ShE75ubmm7QO",
        "outputId": "637f4082-cf67-4f81-d1ed-0801f013bec9"
      },
      "source": [
        "!pip install ffmpeg"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting ffmpeg\n",
            "  Downloading ffmpeg-1.4.tar.gz (5.1 kB)\n",
            "Building wheels for collected packages: ffmpeg\n",
            "  Building wheel for ffmpeg (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for ffmpeg: filename=ffmpeg-1.4-py3-none-any.whl size=6083 sha256=8277dc17d4c0a6805ca80e02bd431e8f11505e97d1107d2fe4aec2c51817cd95\n",
            "  Stored in directory: /root/.cache/pip/wheels/64/80/6e/caa3e16deb0267c3cbfd36862058a724144e19fdb9eb03af0f\n",
            "Successfully built ffmpeg\n",
            "Installing collected packages: ffmpeg\n",
            "Successfully installed ffmpeg-1.4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oAsJjvTnuunM",
        "outputId": "1c8f4ff0-94dd-44c2-f200-a282883b2bc2"
      },
      "source": [
        "!pip install pydub"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pydub\n",
            "  Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
            "Installing collected packages: pydub\n",
            "Successfully installed pydub-0.25.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "9rtV6wwbm7Lh",
        "outputId": "1158a6e3-4734-4066-d55b-615eea29e83b"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "\n",
        "import librosa\n",
        "import librosa.display\n",
        "\n",
        "from pydub import AudioSegment\n",
        "from pydub.utils import make_chunks\n",
        "\n",
        "import fastai\n",
        "from fastai.vision import *\n",
        "fastai.__version__"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'1.0.61'"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8h80QsP1nHFn"
      },
      "source": [
        "learn = load_learner('/content/drive/MyDrive/Colab Notebooks/GBCLessons/Math 2/classifier/')"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dZkyxB5VQSZ0"
      },
      "source": [
        "file_path = '/content/drive/MyDrive/Colab Notebooks/GBCLessons/Math 2/classifier/Data/test_data/'"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u7RnAst4sRHM"
      },
      "source": [
        "import math\n",
        "\n",
        "def classify_speaker(audio_path):\n",
        "  samples, sample_rate = librosa.load(audio_path)\n",
        "\n",
        "  # Create spectrograms to analyze\n",
        "  make_spectrograms(samples, sample_rate)\n",
        "\n",
        "  # Read and tally predictions\n",
        "  prediction = predict_speaker()\n",
        "\n",
        "  # Clean up data\n",
        "  clean_up_spectrograms(samples, sample_rate)\n",
        "\n",
        "  print(f'\\r\\nI think that the speaker is {prediction}.')\n",
        "  \n",
        "def make_spectrograms(samples, sample_rate):\n",
        "  chunk_count = math.floor(len(samples) / sample_rate)\n",
        "\n",
        "  for i in range(chunk_count):\n",
        "    start_timestamp = i * sample_rate\n",
        "    end_timestamp = (i+1) * sample_rate\n",
        "\n",
        "    chunk = samples[start_timestamp:end_timestamp]\n",
        "\n",
        "    mel_spec_power = librosa.feature.melspectrogram(chunk, sr=sample_rate, power=2.0) \n",
        "    mel_spec_db = librosa.power_to_db(mel_spec_power, ref=np.max)\n",
        "\n",
        "    filename = (f'spec_{i}.png')\n",
        "    plt.imsave(filename, mel_spec_db)\n",
        "\n",
        "def predict_speaker():\n",
        "  speaker = ''\n",
        "  predictions = {}\n",
        "  count = 1\n",
        "\n",
        "  for filename in os.listdir('.'):\n",
        "    if filename[-4:] == '.png':\n",
        "      count += 1\n",
        "      img = open_image('/content/' + filename)\n",
        "      speaker_name,_,prob = learn.predict(img)\n",
        "      p = float(torch.max(prob) * 100)\n",
        "      # Only consider value if confidence is above 70%\n",
        "      if p > 70:\n",
        "        print(f'Sample {count} = {speaker_name} ({round(p,2)}% probability)')\n",
        "        if str(speaker_name) not in predictions:\n",
        "          predictions[str(speaker_name)] = round(p,2)\n",
        "        else:\n",
        "          predictions[str(speaker_name)] += round(p,2)\n",
        "\n",
        "  maxval = max(predictions.values())\n",
        "  res = [(k, v) for k, v in predictions.items() if v == maxval]\n",
        "  return res[0][0]\n",
        "\n",
        "def clean_up_spectrograms(samples, sample_rate):\n",
        "  chunk_count = math.floor(len(samples) / sample_rate)\n",
        "  for i in range(chunk_count):\n",
        "    filename = (f'spec_{i}.png')\n",
        "    os.remove(filename) "
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2jiEj_cWSa0n",
        "outputId": "dd044de7-3495-4239-af18-4052e86c79ed"
      },
      "source": [
        "classify_speaker(file_path + 'dan_sample.wav')"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 2 = Juan (83.38% probability)\n",
            "Sample 5 = Dan (99.74% probability)\n",
            "\r\n",
            "I think that the speaker is Dan.\n"
          ]
        }
      ]
    }
  ]
}