{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "03 - Spectrogram Classification Example.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yq_t4O4bmuck",
        "outputId": "b9838d70-9094-483b-9a55-1cf9c04d84af"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ShE75ubmm7QO",
        "outputId": "69a46bad-4ad0-4e1b-fce6-bf1ad02d442a"
      },
      "source": [
        "!pip install ffmpeg"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: ffmpeg in /usr/local/lib/python3.7/dist-packages (1.4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oAsJjvTnuunM",
        "outputId": "ad9662b6-46dd-4e86-c94a-f1398b19fe1b"
      },
      "source": [
        "!pip install pydub"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pydub in /usr/local/lib/python3.7/dist-packages (0.25.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "9rtV6wwbm7Lh",
        "outputId": "6d3edbd3-59b9-42a2-9e13-fe444f523971"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "\n",
        "import librosa\n",
        "import librosa.display\n",
        "\n",
        "from pydub import AudioSegment\n",
        "from pydub.utils import make_chunks\n",
        "\n",
        "import fastai\n",
        "from fastai.vision import *\n",
        "fastai.__version__"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'1.0.61'"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8h80QsP1nHFn"
      },
      "source": [
        "learn = load_learner('/content/drive/MyDrive/Colab Notebooks/GBCLessons/Math 2/classifier/')"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dZkyxB5VQSZ0"
      },
      "source": [
        "file_path = '/content/drive/MyDrive/Colab Notebooks/GBCLessons/Math 2/classifier/Data/test_data/'"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u7RnAst4sRHM"
      },
      "source": [
        "import math\n",
        "\n",
        "def classify_speaker(audio_path):\n",
        "  samples, sample_rate = librosa.load(audio_path)\n",
        "\n",
        "  # Create spectrograms to analyze\n",
        "  make_spectrograms(samples, sample_rate)\n",
        "\n",
        "  # Read and tally predictions\n",
        "  prediction = predict_speaker()\n",
        "\n",
        "  # Clean up data\n",
        "  clean_up_spectrograms(samples, sample_rate)\n",
        "\n",
        "  print(f'\\r\\nI think that the speaker is {prediction}.')\n",
        "  \n",
        "def make_spectrograms(samples, sample_rate):\n",
        "  chunk_count = math.floor(len(samples) / sample_rate)\n",
        "\n",
        "  for i in range(chunk_count):\n",
        "    start_timestamp = i * sample_rate\n",
        "    end_timestamp = (i+1) * sample_rate\n",
        "\n",
        "    chunk = samples[start_timestamp:end_timestamp]\n",
        "\n",
        "    mel_spec_power = librosa.feature.melspectrogram(chunk, sr=sample_rate, power=2.0) \n",
        "    mel_spec_db = librosa.power_to_db(mel_spec_power, ref=np.max)\n",
        "\n",
        "    filename = (f'spec_{i}.png')\n",
        "    plt.imsave(filename, mel_spec_db)\n",
        "\n",
        "def predict_speaker():\n",
        "  speaker = ''\n",
        "  prediction = 0\n",
        "  predictions = {}\n",
        "  count = 1\n",
        "\n",
        "  for filename in os.listdir('.'):\n",
        "    if filename[-4:] == '.png':\n",
        "      count += 1\n",
        "      img = open_image('/content/' + filename)\n",
        "      speaker_name,_,prob = learn.predict(img)\n",
        "      p = float(torch.max(prob) * 100)\n",
        "      # Only consider value if confidence is above 70%\n",
        "      if p > 70:\n",
        "        print(f'Sample {count} = {speaker_name} ({round(p,2)}% probability)')\n",
        "        if str(speaker_name) not in predictions:\n",
        "          predictions[str(speaker_name)] = 1\n",
        "        else:\n",
        "          predictions[str(speaker_name)] += 1\n",
        "\n",
        "  return max(predictions)\n",
        "\n",
        "def clean_up_spectrograms(samples, sample_rate):\n",
        "  chunk_count = math.floor(len(samples) / sample_rate)\n",
        "  for i in range(chunk_count):\n",
        "    filename = (f'spec_{i}.png')\n",
        "    os.remove(filename) "
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oNcnZ64GQDTr",
        "outputId": "38c2f014-6f48-45aa-965c-a9887fb181c9"
      },
      "source": [
        "classify_speaker(file_path + 'Juan.wav')"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 2 = Juan (84.96% probability)\n",
            "Sample 4 = Juan (72.61% probability)\n",
            "Sample 5 = Juan (82.35% probability)\n",
            "Sample 6 = Dan (99.45% probability)\n",
            "Sample 7 = Dan (93.39% probability)\n",
            "Sample 8 = Hom (74.76% probability)\n",
            "Sample 9 = Dan (84.36% probability)\n",
            "Sample 10 = Juan (99.12% probability)\n",
            "Sample 12 = Ed (75.81% probability)\n",
            "Sample 14 = Dan (95.79% probability)\n",
            "\r\n",
            "I think that the speaker is Juan.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0weuHuWyQc9Q",
        "outputId": "fb22b1ea-cb3b-4f53-b3ce-0e4bad3817d4"
      },
      "source": [
        "classify_speaker(file_path + 'Hom_test.wav')"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 3 = Hom (95.55% probability)\n",
            "Sample 5 = Hom (98.77% probability)\n",
            "Sample 6 = Ed (79.94% probability)\n",
            "Sample 7 = Hom (98.27% probability)\n",
            "\r\n",
            "I think that the speaker is Hom.\n"
          ]
        }
      ]
    }
  ]
}